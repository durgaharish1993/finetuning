{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import wandb  # Import the wandb library\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, TrainingArguments\n",
    "from adapters import AutoAdapterModel, AdapterConfig, AdapterTrainer\n",
    "from adapters.composition import Stack\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device running on -----------------------> cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bd3b910f3345f8a3c0d9b931d668b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5ca55d33f40c5841116b2d846a5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertAdapterModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15d3ed3544241d7960be2ac1e7a5097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edbe2fd543544189f2ff4cea2b7b311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e434a9aab8df4720946599ae342a48d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19fca4036f74087a3a72030d9d338cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e7616999a3483980b7737e6d21373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e523a0d1bbb146f09d1a54ce1cc277c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e2e2f2465d4d5298b791aa3c4119fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a8e752849647a78301d5c2ef55f144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ec28b4291e462b9ba37c54a9c9a37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a172183623e041fe9eb08bfa846e32b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc191bbc2cd4e4095899a831e3b1517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c58c43e0e64467994fb75885cdf37b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c0229282aa494bb2d89a2464308d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/finetuning/.venv/lib/python3.10/site-packages/adapters/composition.py:186: FutureWarning: Passing list objects for adapter activation is deprecated. Please use Stack or Fuse explicitly.\n",
      "  warnings.warn(\n",
      "/root/finetuning/.venv/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/4210 22:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.246904</td>\n",
       "      <td>0.910550</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.932432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.242401</td>\n",
       "      <td>0.911697</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.899782</td>\n",
       "      <td>0.930180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'adapter1'.\n",
      "/root/finetuning/.venv/lib/python3.10/site-packages/adapters/loading.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_file, map_location=\"cpu\")\n",
      "Overwriting existing adapter 'adapter2'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.24240106344223022, 'eval_accuracy': 0.911697247706422, 'eval_f1': 0.9147286821705426, 'eval_precision': 0.8997821350762527, 'eval_recall': 0.9301801801801802, 'eval_runtime': 4.3438, 'eval_samples_per_second': 200.747, 'eval_steps_per_second': 6.446, 'epoch': 2.0}\n",
      "Input: This movie was fantastic!\n",
      "Prediction: Positive\n",
      "Confidence: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup and Imports\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device running on -----------------------> {device}\")\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "#wandb.init(project=\"sentiment-analysis-adapter\", entity=\"adapterrun\", settings=wandb.Settings(init_timeout=600, _service_wait=600))\n",
    "wandb.init(project=\"sentiment-analysis-adapter\", entity=\"adapterrun\",mode=\"disabled\")\n",
    "\n",
    "\n",
    "# 2. Load Model and Tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoAdapterModel.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 3. Load Dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# 4. Tokenize Dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 5. Add Adapters\n",
    "adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=16)\n",
    "model.add_adapter(\"adapter1\", config=adapter_config)\n",
    "model.add_adapter(\"adapter2\", config=adapter_config)\n",
    "model.add_classification_head(\"sst2\", num_labels=2)\n",
    "\n",
    "# 6. Set Active Adapters and Train Adapter\n",
    "model.set_active_adapters(Stack(\"adapter1\", \"adapter2\"))\n",
    "model.train_adapter([\"adapter1\", \"adapter2\"])\n",
    "\n",
    "# 7. Prepare for Training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Log hyperparameters to W&B\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": training_args.learning_rate,\n",
    "    \"num_train_epochs\": training_args.num_train_epochs,\n",
    "    \"train_batch_size\": training_args.per_device_train_batch_size,\n",
    "})\n",
    "\n",
    "# 8. Define Metrics Function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 9. Initialize Trainer\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 10. Train the Model and log loss to W&B\n",
    "trainer.train()\n",
    "\n",
    "# 11. Evaluate the Model and log evaluation metrics to W&B\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")\n",
    "wandb.log(eval_results)\n",
    "\n",
    "# 12. Inference\n",
    "text = \"This movie was fantastic!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=-1)\n",
    "    label = torch.argmax(predictions, dim=-1)\n",
    "\n",
    "print(f\"Input: {text}\")\n",
    "print(f\"Prediction: {'Positive' if label.item() == 1 else 'Negative'}\")\n",
    "print(f\"Confidence: {predictions[0][label.item()].item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model components: 'NoneType' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "# Save adapters and head for future use\n",
    "save_directory = \"./adapters_save_directory\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "model.save_all_adapters(save_directory)\n",
    "model.save_head(os.path.join(save_directory, \"sst2_head\"))\n",
    "\n",
    "# 14. Load the Model and Adapters (for future use)\n",
    "loaded_model = AutoAdapterModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "try:\n",
    "    loaded_model.load_adapter(os.path.join(save_directory, \"adapter1\"))\n",
    "    loaded_model.load_adapter(os.path.join(save_directory, \"adapter2\"))\n",
    "    \n",
    "    # Ensure that the head is loaded correctly with a check for its existence.\n",
    "    head_path = os.path.join(save_directory, \"sst2_head\")\n",
    "    \n",
    "    if os.path.exists(head_path):\n",
    "        loaded_model.load_head(head_path)\n",
    "        print(\"Head loaded successfully.\")\n",
    "        \n",
    "        loaded_model.set_active_adapters(Stack(\"adapter1\", \"adapter2\"))\n",
    "        \n",
    "    else:\n",
    "        print(f\"Warning: Head not found at {head_path}. Please check if it was saved correctly.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model components: {e}\")\n",
    "\n",
    "# Finish the W&B run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
